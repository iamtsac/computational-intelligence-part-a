\documentclass[12pt,a4paper]{article}

\usepackage[utf8]{inputenc}
\usepackage[greek,english]{babel}
\usepackage{float}
\usepackage[export]{adjustbox}
\usepackage{sans}
\usepackage{kerkis} 
%\usepackage{sans}
%\usepackage[LGRgreek]{mathastext}   
\usepackage{graphicx}
\usepackage{enumerate}
%\usepackage{enumitem}  
\usepackage{amsmath}
\usepackage{hyperref,xcolor} 
\usepackage{subcaption}

\hypersetup{
    colorlinks,
    linkcolor={black!50!black},
    citecolor={blue!50!black}, urlcolor={cyan!80!black},
}

\newcommand{\en}{\selectlanguage{english}} 
\newcommand{\tl}{\textlatin} 
\newcommand{\gr}{\selectlanguage{greek}}   
\newcommand{\code}[1]{\texttt{#1}}         
%\newcommand{\tsuper}{\textsuperscript} \newcommand{\tsub}{\textsubscript}
\renewcommand{\labelenumi}{\alph{enumi}}

 \renewcommand{\thesection}{\arabic{section}.} 
% \renewcommand{\thesubsection}{\arabic{subsection}.}


\gr \title{{\bf \includegraphics[scale=1.0]{images/up_landscape.jpg} \\ ΤΜΗΜΑ ΜΗΧΑΝΙΚΩΝ ΗΛΕΚΤΡΟΝΙΚΩΝ ΥΠΟΛΟΓΙΣΤΩΝ ΚΑΙ ΠΛΗΡΟΦΟΡΙΚΗΣ  \\ \vspace{3cm}Αναφορά Εργαστηριακής Άσκησης Μέρος Α' \\ Υπολογιστική Νοημοσύνη}}
\author{Κωνσταντίνος Τσάκωνας \\ Α.Μ.: 1059666}
\date{Ακαδημαϊκό έτος 2020-21\\ Εαρινό Εξάμηνο}

\begin{document}

    \gr \maketitle \newpage

    \tableofcontents  \newpage

    \section*{\tl{Repository} \gr Κώδικα}
        Για την ανάπτυξη της άσκσης χρησιμοποιήθηκε η γλώσσα \tl{Python} με τις βιβλιοθήκες \tl{Tensorflow, numpy, scikit-learn, pandas} και \tl{matplotlib}. Παρακάτω υπάρχει το \tl{repository} του κώδικα στο \tl{github} και το \tl{link} ενός  \tl{shared} φακέλου στο \tl{google drive} σε περίπτωση που υπάρχει κάποιο πρόβλημα με το πρώτο. \\
        \underline{\tl{\textbf{\url{https://github.com/iamtsac/computational-intelligence-part-a}}}}

    \section{Προεπεξεργασία και Προετοιμασία δεδομένων.} 
    \begin{enumerate}
        \item 
        Το σύνολο των δεδομένων μας αποτελείται από $785$ στήλες. Στην πρώτη στήλη του αρχείου \tl{csv} ο περιέχεται αριθμός που απεικονίζεται στην εικόνα, ο οποίος είναι το  \tl{label} για το νευρωνικό. Οι υπόλοιπες στήλες αποτελούν τα \tl{pixels} της εικόνας. Οπότε το νευρωνικό μας θα έχει ως είσοδο τις στήλες που περιέχουν τα \tl{pixels} και θα εκπαιδευτεί στα δεδομένα του \tl{label}. Στο κώδικα εργαζόμαστε ως εξής, αφού φορτώσουμε τα δεδομένα του \tl{csv(train\_csv)}, χωρίζουμε το \tl{y(label)} από το \tl{x(pixels)}. Στη συνέχεια μετασχηματίζουμε τη λίστα της εισόδου σε ένα ώστε να περιέχει $60.000$ μητρώα $28\times28$ διαστάσεων. Τη παραπάνω εργασία εφαρμόζουμε και στα δεδομένα που έχουμε για τον έλεγχο. Μέτα από τα παραπάνω θα προκύψει μια δομή δεδομένων διαστάσεων ($6000,28,28$) όπου κάθε θέση θα περιέχει στοιχεία της μορφής:
        \begin{equation*}
        X_i = 
        \begin{bmatrix}
            pixel_{1,1} & pixel_{1,2} & \cdots & pixel_{1,28} \\
            pixel_{2,1} & pixel_{2,2} & \cdots & pixel_{2,28} \\
            \vdots      & \vdots      & \ddots & \vdots  \\
            pixel_{28,1} & pixel_{28,2} & \cdots & pixel_{28,28} 
        \end{bmatrix} 
        \end{equation*}
        Στη συνέχεια πρέπει να εφαρμόσουμε μεθόδους για να αλλάξουμε την κλίμακα των δεδομένων για να έχουμε καλύτερη απόδοση στο νευρωνικό μας. Η επιλογή της μεθόδου εξαρτάται από τα δεδομένα που έχουμε. Τρείς τέτοιοι μέθοδοι είναι το Κεντράρισμα, η Κανονικοποίηση και η Τυποποίηση. Οι τεχνικές αυτές χρησιμοποιούνται όταν το \tl{dataset} περιέχει δεδομένα σε διαφορετικές μονάδες μέτρησης, π.χ. ύψος και βάρος.\\ Με την τεχνική της τυποποίησης δίνουμε στα δεδομένα μας μηδενική μέση τιμή και μοναδιαία διακύμναση και η μετατροπή γίνεται από τον τύπο $$x_{stand}= \frac{x - mean(x)}{standard \, deviation(x)}$$ Κάνοντας αυτό δείχνει ότι υποθέτουμε τα δεδομένα μας ακολουθούν \tl{Gaussian} κατανομή και για να εποφεληθούμε από αυτή την προεπεξεργασία πρέπει οι τιμές των δεδομένων μας να είναι αρκετά μικρές, περίπου της κλίμακας $[-3.0,3.0]$.\\ Κατά την κανονικοποίηση μεταφέρουμε της τιμές των δεδομένων από την κλίμακα $[0,255]$, βάση το πρόβλημα μας, στη κλίμακα $[0,1]$. Η τεχνική αυτή εφαρμόζεται σε περιπτώσεις που δεν γνωρίζουμε τι κατανομή ακολουθούν τα δεδομένα μας πράγμα που ισχύει και στη δική μας περίπτωση. Η κανονικοποίηση αυτή έχει ένα μειoνέκτημα, δεν διαχειρίζεται καλά τα \tl{outliers}, αλλά αυτό δεν αποτελεί πρόβλημα στο δικό μας \tl{dataset} η πληροφορια στην εικόνα(κλίμακα του γκρι) δεν εκτείνεται σε όλο το μητρώο, βρίσκεται κυρίως στο κέντρο του.\\ Το κεντράρισμα αφαιρεί από τα \tl{pixels} το μέσο όρο των τιμών τους με αποτέλεσμα οι εικόνες που είναι κεντραρισμένες να έχουν μέση τιμή μηδέν. Αυτή η τεχνική βρίσκει εφαρμογή συνήθως σε δεδομένα που οι τιμές διακυμένονται σε θετικές και αρνητικές τιμές και εφαρμόζεται ώστε τα δεδομένα να αποκτήσουν μια συμμετρία γύρω από το μηδέν ώστε οι τιμές των δεδομένων να μην είναι πολύ υψηλές. Με αυτό τον τρόπο τα νευρωνικά δίκτυα που εκπαιδεύονται σε τέτοιου είδους δεδομένα δείχνουν να συγκλίνουν γρηγορότερα.\\ Στο πρόβλημα μας θα χρησιμοποιήσουμε την κανονικοποίηση διότι δεν γνωρίζουμε τη κατανομή των δεδομένων στην εικόνα, η κλίμακα των δεδομένων είναι στο διάστημα $[0,255]$ και αυτή η προεπεξεργασία ενισχύει στη σταθερότητα και την ταχύτητα του \tl{back-propagation} που θα χρησιμοποιήσουμε στο νευρωνικό μας.
        \item Για το συγκεκριμένο ερώτημα χωρίσαμε τα $60.000$ δείγματα σε $5$ κομμάτια. Αφού έγινε ο διαχωρισμός παίρνουμε το κάθε κομμάτι που προκύπτει από την διάσπαση και κάνουμε επικύρωση με τα υπόλοιπα. Ουσιαστικά χρησιμοποιώντας μία επανάληψη είχαμε σε κάθε εκπαίδευση του μοντέλου $48000$ δεδομένα εκπαίδευσης και $12000$ δεδομένα επικύρωσης. Με αυτό το τρόπο δίνουμε στο μοντέλο μας σε δεδομένα επικύρωσης που δεν έχει ξαναδεί. Έτσι μπορούμε να αξιολογήσουμε πως θα ανταποκριθεί το μοντέλο μας σε πραγματικές συνθήκες και μπορούμε επίσης σε περίπτωση που έχουμε να επιλέξουμε μεταξύ αρχιτεκτονικών να συγκρίνουμε τα αποτελέσματα τους από το \tl{Cross-Validation } και να διαλέξουμε την καλύτερη.
    \end{enumerate}

    \section{Επιλογή Αρχιτεκτονικής.}

    \begin{enumerate}[a]
        \item Η χρήση των \tl{loss function} καθορίζει το σφάλμα ή καλύτερα την απόκλιση που έχει η έξοδος μας από την επιθύμητη και με αυτή τη πληροφορία το δίκτυο μας προσαρμόζει τα βάρη στους νευρώνες ώστε να πλησιάσει όσο το δυνατόν περισσότερο αυτή την επιθυμητή έξοδο. Το \tl{MSE} αυτό που μας δείχνει για το μοντέλο μας είναι, ότι όσο μικραίνει το \tl{MSE} τόσο πιο κοντά είναι η έξοδο μας στο επιθυμητό αποτέλεσμα. Από την άλλη το \tl{CE} χρησιμοποιείται σε προβλήματα κατηγοριοποίησης. Ουσιαστικά είναι η διαφορά δύο κατανομών πιθνανοτήτων και πρακτικά αυτό που κάνει η συνάρτηση κόστους \tl{Cross-Entropy} είναι να δέχεται τις πιθανότητες που προκύπτουν από το επίπεδο εξόδου της μορφής $[x_1\, x_2\, x_3]^T$ και να βρεί τη διαφορά ώστε η εξόδος να γίνει ίδια με την επιθυμήτη κωδικοποίηση του \tl{label} , π.χ. $[1\, 0\, 0 ]^T$.
        Η επιλογή μίας συνάρτησης κόστους εξαρτάται κυρίως από την συνάρτηση ενεργοποίησης που έχουμε στο επίπεδο εξόδου, στο δικό μας πρόβλημα ιδανική  \tl{loss function} είναι η \tl{CE}.

        \item Το νευρωνικό μας θα έχει πλήθος εισόδων $ 28^2 = 784 $ δηλαδή όσα είναι και  τα \tl{pixels} σε κάθε εικόνα. Ουσιαστικά με αυτό τον τρόπο δίνουμε στο μοντέλο μας σαν είσοδο μία εικόνα και προσπαθεί να κατηγοριοποιήσει σε μια κλάση. 

        \item Στην έξοδο θα χρειαστούμε 10 νευρώνες.  Αυτό συμβαίνει γιατί θέλουμε η έξοδος του νευρωνικού μας να καθορίζει την κλάση που ανήκει η εικόνα που δώσαμε σαν είσοδο.

        \item Στους κρυφούς κόμβους η συνάρτηση ενεργοποίησης που διαλέξαμε είναι η \tl{ReLU}. Η απόφαση για την συνάρτηση του κρυφού επιπέδου είναι αρκετά εύκολη, αρκεί να παρατηρήσουμε την γραφική παράσταση της συνάρτηση και το είδος των δεδομένων. Τα δεδομένα μας είναι εικόνες, από \tl{pixels} οι τιμές των οποίων μετά τη κανονικοποίηση κυμαίνονται στο διάστημα $[0,1]$. Ο τύπος της συνάρτησης \tl{ReLU} είναι ο εξής: 
        $$ f(x)=\max(0,x)$$ \includegraphics[ height=6cm, center]{images/relu_graph.png} \\ 
        Χρησιμοποιώντας τη \tl{ReLU} πετυχαίνουμε αρκετά πράγματα εξαιτίας της φύσης του συνόλου δεδομένων που έχουμε. Αρχικά τα δεδομένα είναι αρκετά αραιά, οπότε για κάθε είσοδο δεν θα ενεργοποιούνται όλοι οι νευρώνες, με αποτέλεσμα οι τιμές που δεν προσφέρουν κάποια πληροφορία στο νευρωνικό να μην επηρεάζουν την εκπαίδευση. Επίσης τα μητρώα έχουν τις τιμές που μας ενδιαφέρουν κοντά στο κέντρο, οπότε κατά την πρόοδο της εκπαίδευση θα δούμε μεγάλη βελτίωση αφού θα είναι αρκετά εύκολο για το νευρωνικό να τοποθετήσει τα σωστά βάρη στους κόμβους. Τέλος προσφέρει πολύ μικρή υπολογιστική πολυπλοκότητα στο δίκτυο μας, αφού το μόνο που κάνει είναι απλά μία σύγκριση. 

        \item Στο επίπεδο εξόδου θα χρησιμοποιήσουμε την συνάρτηση \tl{Softmax}, διότι συναρτήσεις όπως  η σιγμοειδής δεν μπορεί να μας βοηθήσει σε ένα πρόβλημα κατηγοριοποίησης σε περισσότερες από δύο κλάσεις όπως αυτό που έχουμε εδώ.  Αυτό που κάνει η \tl{Softmax} και μας είναι απαραίτητο στο συγκεκριμένο πρόβλημα είναι ότι στη έξοδο συμπυκνώνει τις τιμές των \tl{logits} μεταξύ του διαστήματος $[0,1]$ ώστε το άθροισμα των εξόδων να ισούται με $1$. Άρα πρακτικά η συνάρτηση μας δίνει σαν έξοδο τις πιθνανότητες για κάθε κατηγορία ώστε η είσοδος μας να ανήκει σε αυτή.

        \item Για τα παρακάτω αποτελέσματα χρησιμοποιήθηκαν 30 εποχές εκπαίδευση.

            \begin{tabular}{|c | c | c | }
                \hline
                Αριθμός νευρώνων στο κρυφό επίπεδο & \tl{CE loss} & \tl{MSE} \\
                \hline
                $H_1 = O$       & 0,487 & 0,087 \\ 
                $H_1 = (I+O)/2$ & 0,385 & 0,0832 \\ 
                $H_1 = I+O$     & 0,378 & 0,0833 \\
                \hline 
            \end{tabular} \\
            
            Παρακάτω φαίνονται οι γραφικές παραστάσεις: 
            \begin{figure}[H]
                \raggedright
                    \begin{subfigure}[t]{0.5\textwidth}
                        \includegraphics[width=10cm,height=7cm,left]{images/10.png}
                    \end{subfigure}
                    \begin{subfigure}[t]{0.5\textwidth}
                        \includegraphics[width=10cm,height=7cm,left]{images/397.png} 
                    \end{subfigure}
                    \begin{subfigure}[t]{0.5\textwidth}
                        \includegraphics[width=10cm,height=7cm,left]{images/794.png} 
                    \end{subfigure}
            \end{figure}

            \begin{enumerate}[i)]
                \item  Από τα παραπάνω αποτελέσματα παρατηρούμε ότι η εκπαίδευση που είχε πλήθος κρυφών κόμβων ίσο με τον αριθμό των εξόδων παρουσίασε μεγαλύτερο λάθος. Οι υπόλοιπες δύο μετρήσεις είχαν πλήθος κόμβων αρκετά μεγαλύτερο του αριθμού των εξόδων και παρατηρούμε ότι το λάθος σε αυτές τις μετρήσεις είναι μικρότερο. Το οποίο είναι αναμενόμενο αφού όσους περισσότερους κόμβους έχουμε στο κρυφό επίπεδο τόσο πιο πολλές διασυνδέσεις θα έχει το νευρωνικό μας δίκτυο με αποτέλεσμα να έχει καλύτερη ακρίβεια. Ένας σημαντικός παράγοντας όμως είναι και ο χρόνος που χρειάστηκε να εκπαιδευτεί το νευρωνικό μας. Περισσότερων χρόνο κατανάλωσαν το νευρωνικό που είχε $794$ κρυφούς κόμβους, οπότε βέλτιστος αριθμός κόμβος είναι $H_1 = 397$ αφού η διαφορά στο \tl{loss} είναι ελάχιστη αλλά η ταχύτητα εκπαίδευσης σαφώς μεγαλύτερη.
                \item Εστιάζοντας στη συνάρτηση κόστους κάποιος θα μπορούσε να πει ότι με βάση \tl{MSE} το νευρωνικό μας κάνει πολύ σπάνια λάθος, πράγμα που δεν είναι σωστό. Διότι παρατηρήθηκε ότι ναι μεν η συνάρτηση κόστους \tl{MSE}  μπορεί να δείχνει ότι το λάθος του νευρωνικού μας είναι σχεδόν μηδενικό αλλά η ακρίβεια του ήταν κάκιστη. Το αποτέλεσμα αυτό ήταν αρκετά προβλέψιμο αφού το η συνάρτηση κόστους \tl{MSE}  δεν είναι η κατάλληλη συνάρτηση για προβλήματα ταξινόμησης σε κλάσεις αφού δεν "τιμωρεί" σωστά τις λάθος ταξινομήσεις εξαιτίας του αποτελέσματος που προκύπτει από το επίπεδο εξόδου βάση την συναρτησης ενεργοποίησής του. Από την άλλη η συνάρτηση κόστους \tl{CE} αντικατοπτρίζει την πραγματικότητα της απόδοσης του νευρωνικού μας αφού η λειτουργία της απευθύνεται σε προβλήματα ταξινόμησης όπως το δικό μας. Ο λόγος που καθιστά την \tl{CE} καταλληλότερη από την \tl{MSE} αναφέρεται παραπάνω στο ερώτημα Α3.α.
                \item Παρατηρώντας τις γραφικές παραστάσεις βλέπουμε ότι τις πρώτες 10 εποχές η ταχύτητα σύγκλισης είναι μεγαλύτερη από τις υπόλοιπες. Αυτό συμβαίνει διότι αρχικά το νευρωνικό μας δεν έχει τοποθετήσει κάποια βάρη στους νευρώνες. Με αποτέλεσμα αρχικά να κάνει αρκετά λάθη αλλά καθώς επέρχονται οι εποχές και μετά από τις συνεχείς διορθώσεις βαρών φθάνει σε κάποιο σημείο όπου οι μεταβολές στα βάρη είναι μικρότερες, για αυτό και παρατηρούμε την καμπύλη στις τελευταίες εποχές να μεταβάλλεται ελάχιστα.
            \end{enumerate}

        \item Αρχικά πρέπει να ορίσουμε το καινούργιο κρυφό επίπεδο και τη συνάρτηση ενεργοποίησής τους. Αρχικά στο μοντέλο μας προσθέσαμε ένα πλήρης διασυνδεδεμένο επίπεδο(\tl{Dense Layer}) και στη συνέχεια πειραματιστήκαμε με την συνάρτηση ενεργοποίησής. Οι συναρτήσεις που δοκιμάστηκαν ήταν οι \tl{tanh, Sigmoid} και \tl{ReLU }. Από αυτές η \tl{Sigmoid} είχε την χειρότερη χειρότερη απόδοση με λάθος που έφτανε κοντά στο 0,6. Η \tl{tanh} είχε λίγο χειρότερη απόδοση από την \tl{ReLU}, οπότε καταλήξαμε να χρησιμοποιήσουμε την \tl{ReLU}. Το τελευταίο κομμάτι που απομένει για το δεύτερο κρυφό επίπεδο είναι να καθορίσουμε τον αριθμό των κόμβων. Έχοντας δοκιμάσει αρκετά πλήθη κόμβων, βάση απόδοσης καταλήξαμε στο αριθμό $128$, που είχε την καλύτερη απόδοση, παρόλα αυτά η διαφορά στην απόδοση μεταξύ του πλήθους των κόμβων ήταν ελάχιστη αλλά επίσης παρατηρείται ότι δεν υπάρχει τεράστια βελτίωση από το προηγούμενο ερώτημα που είχαμε ένα κρυφό επίπεδο. Ο λόγος που οφείλεται αυτό έχει να κάνει και με την φύση του \tl{dataset} το οποίο είναι αρκετά \tl{optimized} για τη δημιουργία ενός μοντέλου που κάνει \tl{classification}. Τέλος δεν υπάρχει κάποιος γενικός κανόνας για το πως καθορίζεται ο αριθμός των κόμβων, αλλά γενικά μπορούμε να πούμε ότι πρέπει ο αριθμός αυτός να είναι μικρότερος από το πλήθος των εισόδων και μεγαλύτερος από το πλήθος των εξόδων, η τελική απόφαση για το πόσοι κόμβοι θα υπάρχουν προκύπτει μετά από εκτενείς πειραματισμούς. Παρακάτω παρουσιάζεται ο πίνακας με τα αποτελέσματα των σ κόστους μερικών από των πειραμάτων που έγιναν. \\ 

            \begin{tabular}{|c | c | c | }
                \hline
                Αριθμός νευρώνων στο κρυφό επίπεδο & \tl{CE loss} & \tl{MSE} \\
                \hline
                $H_2 = 397$ & 0,303 & 0,086 \\ 
                $H_2 = 128$ & 0,290 & 0,085 \\ 
                $H_2 = 512$ & 0,307 & 0,086 \\
                \hline 
            \end{tabular} 
            \\

        \item Για να γίνει σωστή επιλογή ενός κριτηρίου τερματισμού δεν υπάρχει κάποιος γενικός κανόνας, παρόλα αυτά με σωστή παρατήρηση στα πειράματα μας μπορούμε να ορίσουμε ένα τέτοιο κριτήριο. Ένας τρόπος είναι να θέσουμε ένα κατώφλι για την μεταβολή της συνάρτησης κόστους που όταν γίνει μικρότερη από το κατώφλι να θεωρήσουμε ότι ο αλγόριθμος έχει συγκλίνει. Στο πρόβλημα μας χρησιμοποιήσαμε ένα άλλο κριτήριο τερματισμού, βάση το \tl{validation accuracy}  και τη μεταβολή του. Έχουμε ορίσει ότι αν δεν υπάρχει κάποια βελτίωση και το \tl{validation accuracy} παραμένει σταθερό για τρία συνεχόμενα \tl{epochs} τότε θεωρούμε ότι ο αλγόριθμος έχει συγκλίνει. \\ 
        Στο μοντέλο μας μπορούμε να χρησιμοποιήσουμε \tl{early stopping}. Έχοντας το \tl{Cross Validation} ουσιαστικά δημιουργούμε 5 διαφορετικά μοντέλα και επιλέγουμε το καλύτερο, χωρίς όμως να εξαλείφουμε το πρόβλημα του \tl{underfitting} ή του \tl{overfitting}, όποτε με τη χρήση του \tl{early stopping} θα εξασφαλίσουμε ακριβώς αυτό. Παρόλα αυτά ούτε εδώ υπάρχει κάποιος γενικός κανόνας ώστε να βρούμε το κατάλληλο κριτήριο για να σταματήσουμε την εκπαίδευση. Για να θέσουμε κατάλληλο κριτήριο για το πρόωρο σταμάτημα μπορούμε να παρατηρούμε το σφάλμα επικύρωσης, \tl{Validation Error} και όταν αρχίσει να αυξάνεται ενώ το σφάλμα εκπαίδευσης μειώνεται, σταματάμε την εκπαίδευση. Ένας άλλος τρόπος είναι
        να παρατηρούμε την ιδιότητα γενίκευσης του αλγορίθμου,  για να το κάνουμε αυτό πρέπει να εργαστούμε ως εξής: \\ 
        Έστω \tl{$E_{va}(t)$}, το \tl{validation error}, την εποχή \tl{t}. 
        Αν ορίσουμε το ιδανικό σφάλμα ως \tl{$E_{opt}(t)$} που προκύπτει από τον τύπο:
        \begin{equation}
           E_{opt}(t) = min_{t'<=t}(E_{va}(t'))
        \end{equation}
        Ουσιαστικά το \tl{$E_{opt}$} είναι το μικρότερο \tl{validation error} που έχουμε πάρει μέχρι την εποχή \tl{t}, τότε θα μπορούσαμε να πούμε ότι το \tl{Generalization Loss} είναι:
        \begin{equation}
           GL(t)=\frac{E_{va}(t)}{E_{opt}(t)} - 1
        \end{equation}
        Οπότε ένα λογικό κριτήριο για το \tl{early stopping} θα μπορούσε να είναι \tl{$GL(t) < \alpha$}, όπου το $\alpha$ είναι ένα κατώφλι που όταν ξεπεραστεί σημαίνει ότι το δίκτυο μας έχει υποστεί \tl{overfitting} και αρχίζει να χάνει την ικανότητα γενίκευσης. 
        Στο κώδικα μας χρησιμοποιούμε τον πρώτο τρόπο που αναφέρθηκε για μεγαλύτερη διευκόλυνση. Αφού η βιβλιοθήκη \tl{Tensorflow} δεν διαθέτει ξεχωριστά \tl{callback} για το κριτήριο τερματισμού και για το πρόωρο σταμάτημα.

    \end{enumerate}
    \section{Μεταβολές στον ρυθμό εκπαίδευσης και σταθεράς ορμής}
         Ο λόγος που χρειάζεται το να είναι $m<1$ γίνεται αντιληπτός από τον τύπο της συνάρτησης του \tl{Gradiend Descent} λαμβάνοντας υπόψιν και την ορμή. Ο τύπος είναι ο εξής (το $\alpha$ του τύπου είναι το $m$):
        $$ \Delta w_{ji}(n) = \alpha\Delta w_{ji}(n-1) + \eta\delta_j(n)y_i(n) $$
        Εάν στον παραπάνω τύπο $\alpha>1$ τότε κατά την προσαρμογή των βαρών δίνεται μεγαλύτερη βαρύτητα στις προηγούμενες μεταβολές των βαρών αφού το $\alpha$ πολλαπλασιάζεται με το $\Delta w_{ji}(n-1)$. Αύτο θα επηρεάσει κατά πολύ το βήμα που θα κάνει ο αλγόριθμος στην επόμενη εποχή εκπαίδευσης και υπάρχει πιθανότητα να μην συγκλίνει ποτέ, αφού η προσαρμογή των βαρών θα είναι λαθνασμένη. \newpage
        Παρακάτω φαίνονται τα αποτελέσματα του νευρωνικού, οι γραφικές παραστάσεις και τα συμπεράσματα μας.

        \begin{table}[h]
            \centering
            \begin{tabular}{|c | c | c |c | }
                \hline
                η & \tl{m} & \tl{CE loss} & \tl{MSE} \\
                \hline
                0.001 & 0.2 & 0,279 & 0,084 \\ 
                0.001 & 0.6 & 0,207 & 0,070 \\ 
                0.05  & 0.6 & 0,094 & 0,006 \\ 
                0.1   & 0.6 & 0,097 & 0,005 \\
                \hline 
            \end{tabular} 
        \end{table}
        \begin{figure}[H]
            \raggedright
                \begin{subfigure}[t]{0.5\textwidth}
                    \includegraphics[width=10cm,height=5.2cm,left]{images/0.001_0.2.png}
                \end{subfigure}
                \begin{subfigure}[t]{0.5\textwidth}
                    \includegraphics[width=10cm,height=5.2cm,left]{images/0.001_0.6.png}
                \end{subfigure}
                \begin{subfigure}[t]{0.5\textwidth}
                    \includegraphics[width=10cm,height=5.2cm,left]{images/0.05_0.6.png}
                \end{subfigure}
        \end{figure}

        \begin{figure}[h]
            \raggedright
            \begin{subfigure}[t]{0.5\textwidth}
               \includegraphics[width=10cm,height=5.2cm,left]{images/0.1_0.6.png}
            \end{subfigure}
        \end{figure}
        Αρχικά από τον πίνακα σε σύγκριση με τον προηγούμενο παρατηρούμε ότι καθώς το \tl{Learning Rate} και το \tl{Momentum} ανεβαίνουν το σφάλμα μας μειώνεται και στις δύο συναρτήσες κόστους. Στην περίπτωση όμως που το \tl{Learning Rate} είναι $0.1$ που είναι αρκετά μεγάλη τιμή παρατηρούμε οτι το σφάλμα είχε μία μικρή αύξηση. Το \tl{Dataset} που έχουμε είναι αρκέτα ιδανικό για να εκπαιδεύσουμε το δίκτυο μας για αυτό και η αύξηση που προαναφέρθηκε είναι πολύ μικρή, στη περίπτωση όμως που δεν είχαμε ένα ιδανικό \tl{Dataset} τότε το λάθος αυτό θα είχε αυξηθεί πολύ περισσότερο. Αυτό συμβαίνει διότι με αυτό τον ρυθμό μάθησης τα βήματα που κάνει ο αλγόριθμος στην κατάβαση είναι αρκετά μεγάλα με αποτέλεσμα να προσπερνάει τοπικά ελάχιστα και να συγκλίνει πολύ γρήγορα χωρίς όμως να έχει βρεί τη βέλτιστη λύση.\\ Στις γραφικές παραστάσεις παρατηρούμε ότι η κατάβαση στην αρχή της εκπαίδευσης είναι πιο απότομη σε σχέση με τις προηγούμενες και αυτό οφείλεται στην ορμή, όταν όμως ο αλγόριθμος αρχίζει να συγκλίνει η καμπύλη σταθεροποιείται το οποίο και αυτό οφείλεται στην ορμή. Αυτές οι διακυμάνσεις εξαρτόται από το πρόσημο της μερικής παραγώγου του \tl{momentum}.

    \section{Ομαλοποίηση}
        Παρακάτω φαίνονται οι μετρήσεις και γραφικές παραστάσεις σύγκλισης.
       %Κατά την διαδικασία της ομαλοποίησης πρακτικά εμποδίζουμε τα βάρη να πάρουν υψηλές τιμές.
        \begin{table}[h]
            \centering
            \begin{tabular}{|c | c | c | }
                \hline
                \tl{r}  & \tl{CE loss} & \tl{MSE} \\
                \hline
                0.1  & 1,310 & 0,089 \\ 
                0.5  & 2,302 & 0,089 \\ 
                0.9   & 2,302 & 0,089 \\ 
                \hline 
            \end{tabular} 
        \end{table}

        \begin{figure}[H]
            \raggedright
                \begin{subfigure}[t]{0.5\textwidth}
                    \includegraphics[width=10cm,height=5.2cm,left]{images/0.1.png}
                \end{subfigure}
                \begin{subfigure}[t]{0.5\textwidth}
                    \includegraphics[width=10cm,height=5.2cm,left]{images/0.5.png}
                \end{subfigure}
                \begin{subfigure}[t]{0.5\textwidth}
                    \includegraphics[width=10cm,height=5.2cm,left]{images/0.9.png}
                \end{subfigure}
        \end{figure}

        Με βάση τα αποτελέσματα παρατηρούμε ότι το δικτύο μας δεν συγκλίνει ποτέ. Στις γραφικές παραστάσεις του \tl{MSE} μπορεί να φαίνεται ότι συγκλίνει και σχετικά γρήγορα παρόλα αυτά το \tl{accuracy} είναι πολύ μικρό και αυτό φαίνεται στις γραφικές παραστάσεις από το πρόωρο σταμάτημα που κάνει ο αλγόριθμος ένω το έχουμε θέσει 30 εποχές εκπαίδευσης. Κατά την ομαλοποίηση πρακτικά εμποδίζουμε τα βάρη στο δίκτυο μας να πάρουν υψηλές τιμές ώστε να αποφύγουμε την υπερεκπαίδευση. Αν το καταφέρουμε αυτό το δίκτυο μας θα πρέπει να παρατηρήσουμε μια αύξηση στο \tl{loss} αλλά το \tl{validation accuracy}  θα πρέπει να αυξάνεται οπότε με αυτόν το τρόπο καταλαβαίνουμε ότι το δίκτυο όμως αρχίζει να αποκτά την δυνατότητα να γενικεύει. Στο δικό μας πρόβλημα όμως δεν είδαμε τα επιθυμητά αποτελέσματα και ένας λόγος που συμβαίνει αυτό είναι οι αρκετά μεγάλοι συντελεστές φθοράς που θέσαμε. Έχοντας λοιπόν μεγάλους συντελεστές, σε αρκετούς νευρώνες φθείρονται τόσο πολύ τα βάρη που τείνουν στο μηδέν με αποτέλεσμα οι νευρώνες αυτοί να "νεκρώνουν". Όλο αυτό που περιγράφηκε δείχνει ότι χάνονται διασυνδέσεις στο δίκτυο με βάση τις πρώτες εισόδους που δέχεται αλλά σε επόμενες εισόδους αυτές οι διασυνδέσεις ενδέχεται να έχουν πολύ σημαντική πληροφορία για την εκπαίδευση του δικτύου μας. Ακόμα ένας άλλος λόγος που μπορεί να συμβαίνει αυτό είναι λόγω των δεδομένων που έχουμε, τα δεδομένα μας είναι σχετικά περιορίσμενα και μικρά στον αριθμό για ένα τέτοιο είδος ομαλοποίησης οπότε δεν παρέχουν αρκετή πληροφορία για να μπόρεσει το δίκτυο να γενικεύει με αυτούς τους συντελεστές φθοράς.
        Κάνοντας κάποιον πειραματισμό με τιμές μικρότερες από αυτές που δινόνται, παρατηρήθηκαν τα επιθυμήτα αποτελέσματα, δηλαδή το \tl{loss} αυξήθηκε σε σχέση με τα προηγούμενα ερωτήματα αλλά το \tl{validation accuracy} συνεχώς αυξανόταν. Παρακάτω φαίνεται το γράφημα σύγκλισης για τιμή 0.01.  
                   \includegraphics[width=10cm,height=5.2cm,left]{images/0.01.png}



\end{document} 